+++
title = "分布式资源调度"
description = ""
date = 2020-04-08T15:56:17+08:00
weight = 20
draft = false
bref = ""
toc = true
+++

# 分布式深度学习
## 分布式深度学习作业的训练过程
分布式深度学习（DDL）作业的训练过程分为计算阶段和参数同步阶段。计算阶段完成前向传播和反向传播。前向传播阶段将输入经过各层传播后得到最终的预测值，然后计算损失函数的值。反向传播阶段则通过损失函数计算梯度并将梯度逐层传播到上一层，直到传播到输入层。

参数同步阶段则负责将每个计算节点（Worker）上的参数进行同步。一般有两种模型：BSP模型和ASP模型，BSP模型采用同步方式，即等待每个Worker的参数同步之后开始下一轮迭代；ASP模型采用异步方式，即所有Worker以异步的方式更新全局参数，不考虑陈旧参数带来的影响。生产中，BSP模型使用更加广泛。

## 分布式深度学习作业特性
DDL作业需要将数据集反复进行多次训练才能达到一个较好的泛化能力，这个过程是十分耗费时间和资源的。通过观察DDL作业的训练过程，我们总结了以下特性：
- 迭代性。DDL作业需要将数据集反复训练多次以期获得较好的泛化能力，同时，数据集又被切分为许多Mini-batch作为模型的输入，整个过程就是不断地对Mini-batch数据进行训练，所以DDL作业的训练过程具有迭代性。
- 可预测性。由于DDL作业训练过程的迭代性，模型的训练速度、资源占用量、带宽占用量等在每轮迭代过程中都是相似的，因此DDL作业训练过程具有高度可预测性。
- 高计算能力需要。由于神经网络模型需要进行大量的矩阵运算，因此，CPU是无法支撑起巨大的运算量的。一些专门为矩阵运算设计的计算设备，如GPU、TPU等，提升了计算能力，对神经网络模型是十分友好的。

为了明确以上三个特性对训练过程的影响，我们设计了部分实验进行了验证。特性一可由训练代码直接得出，一下是对另外两个特性进行的实验。

针对特性二，我们将ResNet-50模型在GPU上运行20000个Mini-batch来观察训练速度的变化情况。
![图1. ResNet-50的速度变化](../../img/mlhub/schedule/speed_on_gpu.png)
如上图所示，作业的训练速度在整个过程中基本上保持不变。

针对特性三，我们将ResNet-50模型放置在CPU上进行训练。![](../../img/mlhub/schedule/speed_on_cpu.png)
如上图所示，CPU上训练的速度比GPU上训练的速度要慢非常多。

同时，我们比较了参数服务器架构的DDL作业的训练速度与参数服务器（PS）数目和Worker的数目的关系。在PS取值一定时，ResNet-50的训练速度随着Worker变化的关系。![](../../img/mlhub/schedule/ps_stable.png)
由上图可见，随着Worker数目的增加，在我们的集群中，DDL作业的训练速度先增长后下降。同时比较了在Worker数目一定时，ResNet-50的训练速度随着PS变化的关系。
![](../../img/mlhub/schedule/worker_stable.png)如上图所示，DDL作业的训练速度随着PS数目的增加先增长后趋于稳定。

从DDL作业的训练过程来看，计算设备的计算能力、带宽的大小、计算节点的数目等都是影响DDL作业训练速度的因素，同时，数据集中图片的大小、batch size的大小也是影响因素。


# 分布式资源调度
对于DDL作业的调度工作，是近年来学术界和工业界研究的一个重点工作。如何最大化利用集群的资源加速DDL作业的训练过程不仅影响着算法设计的效率，同时也影响着开发的成本。

## 现有方法
Borg、Mesos、Yarn这些都是为处理各种类型的作业而开发的调度器，他们并没有针对DDL作业的特性进行定制调度，因而也无法在调度层面提升DDL作业的训练效率。
Optimus建立了一个数学模型用来预测训练速度，并基于该数学模型，使用贪心的算法进行资源的分配，优化平均作业完成时间。DL$^2$使用强化学习模型进行资源的分配，由于强化学习模型具备在线学习的能力，因此资源调度过程中可以不断地优化强化学习模型，以达到更好地决策性能。
Tiresias根据Gittins index和LAS为每个作业设置优先级（占用GPU数目、占用GPU时间），并根据运行时作业完成时间的变化动态调整作业的优先级，从而实现作业的资源分配。

## MLHub中的调度
MLHub中，我们将根据DDL作业的特性执行用户无感知的调度决策，总和考虑带宽、作业间干扰等因素对DDL作业带来的影响，使得多个用户提交的作业能够被合理分配到资源，优化平均完成时间。
